# train_model ğŸ§ 

The `train_model` module is part of the **Balatro** project.  
Its purpose is to **train an AI model to recognize cards** based on the annotated dataset.  
The trained model can later be used for real-time card identification with `identify_card`.

---

## ğŸš€ Features

- Load annotated dataset created with `annotate_dataset`
- Train a model to recognize cards
- Support for detecting **polychrome variations**
- Save trained models for later inference
- Configurable training parameters (epochs, batch size, etc.)

---

## ğŸ›  Installation

Make sure you are inside the Balatro project folder and dependencies are installed:

```bash
cd balatro
pip install -r requirements.txt
```

---

## ğŸ¯ Usage

Run the module directly:

```bash
python -m train_model
```

### Example workflow

1. Prepare your dataset using:
   - `build_dataset` (capture images)
   - `annotate_dataset` (organize & label)

2. Start training:
   ```bash
   python -m train_model --epochs 20 --batch-size 32
   ```

3. The trained model will be saved in the `models/` directory.

4. Use the trained model with `identify_card` for real-time recognition.

---

## âš™ï¸ Options

- `--epochs <int>` â†’ Number of training epochs (default: 10)  
- `--batch-size <int>` â†’ Batch size for training (default: 32)  
- `--output <path>` â†’ Path to save the trained model (default: `models/card_model.pth`)  

---

## ğŸ”„ Workflow Context

```text
build_dataset  --->  annotate_dataset  --->  train_model  --->  identify_card
```

## File structure and interactions

train_model/
â”œâ”€â”€ train.py              # Main training loop
â”‚   â”œâ”€ parse_args()       # CLI arguments
â”‚   â”œâ”€ load_dataloaders() # Merge labels + create datasets + train/val loaders
â”‚   â”œâ”€ train_one_epoch()  # Training for one epoch
â”‚   â”œâ”€ validate()         # Compute validation loss
â”‚   â”œâ”€ log_epoch_stats()  # Console + TensorBoard logging
â”‚   â”œâ”€ handle_checkpoints() / save_checkpoint()  # Best/periodic model saving
â”‚   â””â”€ main()             # Main loop: epochs, scheduler, early stopping
â”‚
â”œâ”€â”€ dataset.py            # Dataset utilities
â”‚   â”œâ”€ CardDataset        # Loads images and labels
â”‚   â”œâ”€ from_labels_dict() / from_label_paths()  # Constructors
â”‚   â”œâ”€ load_merged_labels()  # Merge original + augmented labels
â”‚   â””â”€ get_train_val_loaders() # Split dataset + create DataLoaders
â”‚
â”œâ”€â”€ train_utils.py        # Training helper utilities
â”‚   â”œâ”€ TrainingState      # Encapsulates model, optimizer, scheduler, scaler, writer, early stopping
â”‚   â”œâ”€ EarlyStopping      # Tracks no-improvement epochs
â”‚   â”œâ”€ build_model()      # Pretrained ResNet18 + replace final layer + move to device
â”‚   â””â”€ prepare_training() # Build model + optimizer + scheduler + scaler + early stopping + TensorBoard
â”‚
â””â”€â”€ train_config.py       # Configs
    â”œâ”€ TransformConfig    # Predefined image transforms (train/test/none)
    â””â”€ Config             # Hyperparameters: epochs, batch_size, learning_rate, val_split, num_classes, transform mapping


# Data Collection & Training Strategy Decisions â€“ Balatro

This document outlines the decisions and trade-offs for building the dataset of cards and training an AI model effectively. The goal is to balance realism, efficiency, and robustness.

---

##  Training strategies

### 1. Framework Choice

**Option: PyTorch**

* **Advantages**:

  * Flexible, great for custom DataLoaders (fits Balatroâ€™s dataset structure).
  * TorchVision has strong support for augmentations.
  * Widely used for research and experimentation.
* **Constraints**:

  * Slightly less â€œplug-and-playâ€ than TensorFlow/Keras.

**Option: TensorFlow / Keras**

* **Advantages**:

  * High-level APIs (`model.fit`) make training easy.
  * Strong visualization/debugging tools (TensorBoard).
* **Constraints**:

  * Harder integration with custom dataset structures.
  * Less flexible for embedding/similarity-based experiments.

âœ… **Decision**: Use **PyTorch** for modularity and flexibility.

---

### 2. Image Size & Preprocessing

**Option: Resize to fixed size (224Ã—224)**

* **Advantages**: Matches pretrained model input; simple pipeline.
* **Constraints**: Minor distortion for non-square cards.

**Option: Keep native aspect ratio, pad to square**

* **Advantages**: Preserves exact proportions.
* **Constraints**: More complex preprocessing; still resized for pretrained models.

âœ… **Decision**: Resize all images to **224Ã—224**, normalized to **ImageNet mean/std**.

---

### 3. Runtime Augmentation

**Option: Only offline augmentation**

* **Advantages**: Fully reproducible dataset; simpler training loop.
* **Constraints**: Limited variety â†’ risk of overfitting.

**Option: Only runtime (on-the-fly) augmentation**

* **Advantages**: Fresh variations each epoch; more robust.
* **Constraints**: Less reproducibility; slower training.

**Option: Hybrid (offline + runtime)**

* **Advantages**: Large reproducible base dataset + stochastic variety at training time.
* **Constraints**: Slightly more complex setup.

âœ… **Decision**: **Hybrid** â†’ offline augmentations expand dataset, runtime augmentations add randomness. Avoid horizontal flips (text orientation issue).

---

### 4. Batch Size & Learning Rate

**Option: Batch size 32, LR 1e-4 (Adam)**

* **Advantages**: Stable, works for most GPUs.
* **Constraints**: May need tuning later.

**Option: Large batch (64â€“128)**

* **Advantages**: Faster per epoch; smoother gradients.
* **Constraints**: Higher memory requirements.

**Option: Small batch (8â€“16)**

* **Advantages**: Works on limited GPUs; more gradient noise (sometimes helps).
* **Constraints**: Slower, noisier convergence.

âœ… **Decision**: Start with **batch size 32**, **LR 1e-4**, **Adam optimizer**. Adjust based on dataset scale and GPU.

---

### 5. Early Stopping & Checkpointing

**Option: No early stopping, fixed epochs**

* **Advantages**: Simple.
* **Constraints**: Risk of overfitting / wasted compute.

**Option: Early stopping (monitor val loss)**

* **Advantages**: Prevents overfitting; saves best model.
* **Constraints**: Slightly more complex.

**Option: Checkpoint every N epochs**

* **Advantages**: Keeps rollback history.
* **Constraints**: Higher disk usage.

âœ… **Decision**: Use **early stopping + best-model checkpoint**. Optionally save periodic checkpoints for debugging.

## Future Considerations

* **Embedding-based similarity search**:

  * Train a feature extractor to produce embeddings for each card.
  * Use cosine similarity or k-NN to identify rare/low-sample cards.
  * Reduces dependency on large datasets for each unique card.

* **Polychrome recognition**:

  * Extend dataset to include polychrome variations.
  * Add separate labels or multi-task outputs for color variants.

* **Few-shot / transfer learning**:

  * For new card releases or low-sample cards, leverage pretrained backbones.
  * Fine-tune embeddings on small subsets.

* **Advanced augmentations**:

  * Lighting, perspective distortion, occlusion.
  * Helps improve model generalization to real gameplay.

* **Logging and experiment tracking**:

  * Keep experiment metadata (hyperparameters, augmentations, results).
  * Facilitates reproducibility and iterative improvements.

---

## Summary

* **Data**: Begin with collection screen captures, expand with gameplay samples.
* **Framework**: PyTorch.
* **Preprocessing**: 224Ã—224, ImageNet normalization.
* **Augmentation**: Hybrid (offline + runtime, no flips).
* **Training defaults**: Batch 32, LR 1e-4, Adam, ~20 epochs.
* **Regularization**: Early stopping + checkpointing.
* **Future-proof**: Embeddings, few-shot learning, polychrome support, advanced augmentation.



---

## ğŸ“Œ Notes

- Currently supports basic image classification workflows.  
- Polychrome recognition is experimental and may require dataset extensions.  
- Future versions may support transfer learning or custom model architectures.  

---

## ğŸ¤ Contributing

Contributions for improving the training pipeline, model accuracy, or adding advanced features (e.g., augmentation, polychrome support) are welcome.  

---

## ğŸ“„ License

Specify your license here (MIT, GPL, etc.).
