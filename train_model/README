# train_model üß†

The `train_model` module is part of the **Balatro** project.  
Its purpose is to **train an AI model to recognize cards** based on the annotated dataset.  
The trained model can later be used for real-time card identification with `identify_card` module.

---

## üöÄ Features

- Load annotated dataset created with `annotate_dataset`
- Train a model to recognize cards
- Support for detecting **polychrome variations**
- Save trained models for later inference
- Configurable training parameters (epochs, batch size, etc.)

---

## üõ† Installation

Make sure you are inside the Balatro project folder and dependencies are installed:

```bash
cd balatro
pip install -r requirements.txt
```

---

## üéØ Usage

Run the module directly:

```bash
python -m train_model
```

Or with arguments (See CLI section)

```bash
python -m train_model --epochs 20 --batch-size 32 --lr 0.0001 --val-split 0.2 --num-classes 50 --log-dir runs/card_training --freeze-backbone --use-augmented

```

### Example workflow

1. Prepare your dataset using:
   - `build_dataset` (capture images)
   - `annotate_dataset` (organize & label)

2. Start training:
   ```bash
   python -m train_model --epochs 20 --batch-size 32
   ```

3. The trained model will be saved in the `models/` directory.

4. Use the trained model with `identify_card` for real-time recognition.

---

## Detailed features

## Balatro Train Module Features

The `train` module provides full functionality to train, validate, and monitor the card recognition model. Its main capabilities include:

### 1. Data Handling

* **Merge Labels:** Combine original and augmented labels into a single mapping for training.
* **Custom Dataset:** `CardDataset` loads images and labels from a dictionary or label files.
* **Train/Validation Split:** Split datasets into train/val sets with optional transforms.
* **Weighted Sampling:** Handle class imbalance with a `WeightedRandomSampler` if requested.
* **Dynamic Augmentation:** Apply train-time image augmentations (configurable via `Config.TRANSFORMS['train']`) to improve generalization.

### 2. Model Management

* **Pretrained Model:** Load a pretrained ResNet18 and replace the final layer to match the dataset‚Äôs number of classes.
* **Device Management:** Automatically uses GPU if available.
* **Freezing Backbone:** Optionally freeze feature extractor layers for fine-tuning only the classifier.

### 3. Training Pipeline

* **Forward & Backward Pass:** Handles normal and mixed-precision training automatically.
* **Validation:** Compute validation loss and optionally additional metrics during evaluation.

### 4. Metrics

* **Top-K Accuracy:** Compute Top-3 accuracy to measure how often the correct label is within the top-k predictions.
* **Confusion Matrix:** Compute class-by-class performance for detailed error analysis.

### 5. Logging & Visualization

* **Console Logging:** Epoch statistics, including train/validation loss and optional metrics.
* **TensorBoard Logging:** Tracks loss, learning rate, and Top-K accuracy. Write to 'runs/' by default.

### 6. Checkpointing

* **Best Model Saving:** Automatically saves the model with the lowest validation loss.
* **Periodic Snapshots:** Saves checkpoints at regular intervals for safety.

### 7. Training Utilities

* **Early Stopping:** Monitors validation loss to stop training if performance stops improving.
* **Learning Rate Scheduling:** Supports StepLR or ReduceLROnPlateau depending on dataset size.
* **Resuming Training:** Load from a checkpoint to continue interrupted training.

### 8. Configurable Parameters

* **From `train_config.Config` :**

  * `EPOCHS` : Default number of training epochs
  * `BATCH_SIZE` : Default batch size
  * `LEARNING_RATE` : Initial learning rate
  * `VAL_SPLIT` : Default fraction of data for validation
  * `NUM_CLASSES` : Number of output classes
  * `TRANSFORMS` : Dictionary of image transformations (`train` / `test` / `none` / `heavy` / `light`) for dynamic augmentation


## ‚öôÔ∏è Options

* `--epochs` : Number of training epochs (default from `Config.EPOCHS`)
* `--batch-size` : Batch size for training and validation (default `Config.BATCH_SIZE`)
* `--lr` : Learning rate (default `Config.LEARNING_RATE`)
* `--val-split` : Fraction of dataset used for validation (default `Config.VAL_SPLIT`)
* `--num-classes` : Override number of output classes (default `Config.NUM_CLASSES`)
* `--log-dir` : Directory for TensorBoard logs
* `--checkpoint-interval` : Frequency (in epochs) to save periodic snapshots
* `--use-augmented` : Enable augmented labels
* `--freeze-backbone` : Freeze feature extractor layers
* `--resume` : Path to a checkpoint to resume training
* `--use-weighted-sampler` : Enable class-balanced sampling
* `--train-transform` : Override default transform for training (Accept values from Config.TRANSFORMS)
* `--val-transform` : Override default transform for validation (Accept values from Config.TRANSFORMS)

---

## üîÑ Workflow Context

```text
build_dataset  --->  annotate_dataset  --->  train_model  --->  identify_card
```



# Data Collection & Training Strategy Decisions ‚Äì Balatro

This document outlines the decisions and trade-offs for building the dataset of cards and training an AI model effectively. The goal is to balance realism, efficiency, and robustness.

---

##  Training strategies

### 1. Framework Choice

**Option: PyTorch**

* **Advantages**:

  * Flexible, great for custom DataLoaders (fits Balatro‚Äôs dataset structure).
  * TorchVision has strong support for augmentations.
  * Widely used for research and experimentation.
* **Constraints**:

  * Slightly less ‚Äúplug-and-play‚Äù than TensorFlow/Keras.

**Option: TensorFlow / Keras**

* **Advantages**:

  * High-level APIs (`model.fit`) make training easy.
  * Strong visualization/debugging tools (TensorBoard).
* **Constraints**:

  * Harder integration with custom dataset structures.
  * Less flexible for embedding/similarity-based experiments.

‚úÖ **Decision**: Use **PyTorch** for modularity and flexibility.

---

### 2. Image Size & Preprocessing

**Option: Resize to fixed size (224√ó224)**

* **Advantages**: Matches pretrained model input; simple pipeline.
* **Constraints**: Minor distortion for non-square cards.

**Option: Keep native aspect ratio, pad to square**

* **Advantages**: Preserves exact proportions.
* **Constraints**: More complex preprocessing; still resized for pretrained models.

‚úÖ **Decision**: Resize all images to **224√ó224**, normalized to **ImageNet mean/std**.

---

### 3. Runtime Augmentation

**Option: Only offline augmentation**

* **Advantages**: Fully reproducible dataset; simpler training loop.
* **Constraints**: Limited variety ‚Üí risk of overfitting.

**Option: Only runtime (on-the-fly) augmentation**

* **Advantages**: Fresh variations each epoch; more robust.
* **Constraints**: Less reproducibility; slower training.

**Option: Hybrid (offline + runtime)**

* **Advantages**: Large reproducible base dataset + stochastic variety at training time.
* **Constraints**: Slightly more complex setup.

‚úÖ **Decision**: **Hybrid** ‚Üí offline augmentations expand dataset, runtime augmentations add randomness. Avoid horizontal flips (text orientation issue).

---

### 4. Batch Size & Learning Rate

**Option: Batch size 32, LR 1e-4 (Adam)**

* **Advantages**: Stable, works for most GPUs.
* **Constraints**: May need tuning later.

**Option: Large batch (64‚Äì128)**

* **Advantages**: Faster per epoch; smoother gradients.
* **Constraints**: Higher memory requirements.

**Option: Small batch (8‚Äì16)**

* **Advantages**: Works on limited GPUs; more gradient noise (sometimes helps).
* **Constraints**: Slower, noisier convergence.

‚úÖ **Decision**: Start with **batch size 32**, **LR 1e-4**, **Adam optimizer**. Adjust based on dataset scale and GPU.

---

### 5. Early Stopping & Checkpointing

**Option: No early stopping, fixed epochs**

* **Advantages**: Simple.
* **Constraints**: Risk of overfitting / wasted compute.

**Option: Early stopping (monitor val loss)**

* **Advantages**: Prevents overfitting; saves best model.
* **Constraints**: Slightly more complex.

**Option: Checkpoint every N epochs**

* **Advantages**: Keeps rollback history.
* **Constraints**: Higher disk usage.

‚úÖ **Decision**: Use **early stopping + best-model checkpoint**. Optionally save periodic checkpoints for debugging.

## Future Considerations

* **Embedding-based similarity search**:

  * Train a feature extractor to produce embeddings for each card.
  * Use cosine similarity or k-NN to identify rare/low-sample cards.
  * Reduces dependency on large datasets for each unique card.

* **Polychrome recognition**:

  * Extend dataset to include polychrome variations.
  * Add separate labels or multi-task outputs for color variants.

* **Few-shot / transfer learning**:

  * For new card releases or low-sample cards, leverage pretrained backbones.
  * Fine-tune embeddings on small subsets.

* **Advanced augmentations**:

  * Lighting, perspective distortion, occlusion.
  * Helps improve model generalization to real gameplay.

* **Logging and experiment tracking**:

  * Keep experiment metadata (hyperparameters, augmentations, results).
  * Facilitates reproducibility and iterative improvements.

---

## Summary

* **Data**: Begin with collection screen captures, expand with gameplay samples.
* **Framework**: PyTorch.
* **Preprocessing**: 224√ó224, ImageNet normalization.
* **Augmentation**: Hybrid (offline + runtime, no flips).
* **Training defaults**: Batch 32, LR 1e-4, Adam, ~20 epochs.
* **Regularization**: Early stopping + checkpointing.
* **Future-proof**: Embeddings, few-shot learning, polychrome support, advanced augmentation.



---

## üìå Notes

- Currently supports basic image classification workflows.  
- Polychrome recognition is experimental and may require dataset extensions.  
- Future versions may support transfer learning or custom model architectures.  



